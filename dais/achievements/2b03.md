---
layout: splash
permalink: /2b03/
---

# State-action separable and embedding for RL

[Watch the video](https://ibm.box.com/s/azq7j2pthfs9zunvs285dvj9gq0feool) - Check URL

## Military / Coalition Issue
Reinforcement learning (RL) has been widely applied for system control in many domains.  However, state-of-the-art RL often encounters issues such as huge state-action spaces, inefficient knowledge representation of states and actions, and violation of underlying model assumptions. As a result, RL techniques are often computationally complex and require long learning time, thus limiting their applicability to national defence.

## Core idea and key achievements
The DAIS team has developed new techniques to address these RL issues, including state-action space explosion, inefficient knowledge representation of states and actions, learning with sudden changes in operating environments, and violation of underlying model assumptions.  We focus here on two new techniques.  First, a new technique called state-action separable RL (sasRL) has been proposed to separate state transitions from actions taken, while considering impact of actions through simple supervised learning, thus alleviating the issue of large state-action spaces. Second, a new embedding approach has been developed that uses a model of the environment to obtain joint embeddings for states and actions, from which the optimal policy can be learned. In this way, the embedded representations obtained enable better generalization over both states and actions by capturing similarities in the embedding spaces. Both new techniques greatly reduce the computation and learning time, thus extending the applicability of RL.  Please also see the related DAIS Outcomes on “RL for Network Control” and “Joint Reinforcement and Transfer Learning for Fragmented SDC.”

Key achievements include the development of: 
- sasRL technique to overcome huge state-action spaces
- Jointly trained state-action embedding to speed up learning for RL

  ![image info](/dais/achievements/images/2b03-figure1.png)

## Implications for Defence
The new techniques will enable defence to apply RL for real-time control and sharing of infrastructure assets among armed forces. They support efficient, agile and robust configuration and use of resources, which are unmatched by our adversaries. The techniques are also applicable to other systems such as radio spectrum sharing in electromagnetic warfare.

## Readiness & alternative Defence uses - Check URL
TRL 2/3. Both new techniques have been applied to practical problems studied in the literature and the sasRL has been prototyped in the [joint RL-TL for SDC fragmentation](http://sl.dais-ita-org/science-library/paper/doc-6087). They can be readily applied to defence systems.

## Resources and references - Check URLs
[State-action separable RL](https://dais-ita.org/node/5425), [joint state-action embeddings for RL](http://sl.dais-ita.org/science-library/paper/doc-6085), and [RL-TL for SDC fragmentation](http://sl.dais-ita.org/science-library/paper/doc-6087).

## Organisations
Imperial College, IBM US, Yale University, Purdue University, Dstl and ARL
