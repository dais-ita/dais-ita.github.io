---
layout: splash
permalink: /doc-8021/
title: "Gradient-Based Interpretability Methods and Binarized Neural Networks"
---

# Gradient-Based Interpretability Methods and Binarized Neural Networks

<table>
    <tbody>
    <tr>
        <td>Abstract</td>
        <td>Binarized Neural Networks (BNNs) have the potential to revolutionize the way that deep learning is carried out in edge computing platforms. However, the effectiveness of interpretability methods on these networks has not been assessed.
In this paper, we compare the performance of several widely used saliency map-based interpretabilty techniques (Gradient, SmoothGrad and GradCAM), when applied to Binarized or Full Precision Neural Networks (FPNNs). We found that the basic Gradient method produces very similar-looking maps for both types of network. However, SmoothGrad produces significantly noisier maps for BNNs. GradCAM also produces saliency maps which differ between network types, with some of the BNNs having seemingly nonsensical explanations. We comment on possible reasons for these differences in explanations and present it as an example of why interpretability techniques should be tested on a wider range of network types.</td>
    </tr>
    <tr>
        <td>Authors</td>
        <td>
            <ul>
                <li>Amy Widdicombe (UCL)</li>
                <li>Simon Julier (UCL)</li>
            </ul>
        </td>
    </tr>
    <tr>
        <td>Date</td>
        <td>Jun-2021</td>
    </tr>
    <tr>
        <td>Venue</td>
        <td>Proceedings of the ICML 2021 Workshop on Theoretic Foundation, Criticism & Application Trend of Explainable AI</td>
    </tr>
    <tr>
        <td colspan="2">
            <form method="get" action="https://arxiv.org/abs/2106.12569">
                <button type="submit">download paper</button>
            </form>
        </td>
    </tr>
    </tbody>
</table>
