---
layout: splash
permalink: /doc-7128/
title: "Hybrid Analog-Spiking Long Short-Term Memory for Energy Efficient Computing on Edge Devices"
---

# Hybrid Analog-Spiking Long Short-Term Memory for Energy Efficient Computing on Edge Devices

<table>
    <tbody>
    <tr>
        <td>Abstract</td>
        <td>Recurrent neural networks such as Long Short-Term Memory (LSTM) have been used in many sequential learning tasks such as speech recognition and language translation. Running large-scale LSTMs for real-world applications is known to be compute-intensive and often relies on cloud execution. To enable LSTM operations on edge devices that receive inputs in realtime, there is a need to improve LSTM execution efficiency following the limited energy constraint of the mobile platforms. We propose a hybrid analog-spiking LSTM that combines the energy efficiency of spiking neural network (SNN) with the performance efficiency of analog (non-spiking) neural network (ANN). SNN, which processes and represents information as a sequence of sparse binary spikes or events, uses integrate and fire activation, hence consuming low power and energy for realtime inference (batch size of 1). The proposed Analog-Spiking LSTM is derived from a trained LSTM using a novel conversion method that transforms the fully-connected layers and the nonlinearity function compatible for SNNs. We show that the default LSTM non-linearities are sources of output mismatch between the ANN and the SNN. We propose a set of replacement functions that lead to a minimal impact on the output quality of sequential learning problems. Our analyses on sequential image classification on MNIST dataset and sequence-to-sequence translation on the IWSLT14 dataset indicate <1% drop in average accuracy for rowwise and pixel-wise sequential image recognition and <1.5 drop in average BLEU score for the translation task. Implementation of the recognition system with the hybrid analog-spiking LSTM on Intel's spiking processor, Loihi, shows 55.9× improvement in active energy per inference over the baseline system on Intel i7-6700. Based on our analysis, we estimate this benefit to be 3.38× reduction in active energy per inference for the translation task.</td>
    </tr>
    <tr>
        <td>Authors</td>
        <td>
            <ul>
                <li>Kaushik Roy (Purdue)</li>
                <li>Wachirawit Ponghiran (Purdue)</li>
            </ul>
        </td>
    </tr>
    <tr>
        <td>Date</td>
        <td>Feb-2021</td>
    </tr>
    <tr>
        <td>Venue</td>
        <td>2021 Design, Automation & Test in Europe Conference & Exhibition (DATE)</td>
    </tr>
    <tr>
        <td colspan="2">
            <form method="get" action="https://ieeexplore.ieee.org/document/9473953">
                <button type="submit">download paper</button>
            </form>
        </td>
    </tr>
    </tbody>
</table>
