---
layout: splash
permalink: /doc-3382/
title: "Conversational Explanations: Explainable AI through human-machine conversation"
---

# Conversational Explanations: Explainable AI through human-machine conversation

<table>
    <tbody>
    <tr>
        <td>Abstract</td>
        <td>Explainable AI has significant focus within both the research community and the popular press. The tantalizing potential of artificial intelligence solutions may be undermined if the machine processes which produce these results are black boxes that are unable to offer any insight or explanation into the results, the processing, or the training data on which they are based. The ability to provide explanations can help to build user confidence, rapidly indicate the need for correction or retraining, as well provide initial steps towards the mitigation of issues such as adversarial attacks, or allegations of bias. In this tutorial we will explore the space of Explainable AI, but with a particular focus on the role of the human users within the human-machine hybrid team, and whether a conversational interaction style is useful for obtaining such explanations quickly and easily.</td>
    </tr>
    <tr>
        <td>Authors</td>
        <td>
            <ul>
                <li>Dave Braines (IBM UK)</li>
            </ul>
        </td>
    </tr>
    <tr>
        <td>Date</td>
        <td>Apr-2019</td>
    </tr>
    <tr>
        <td>Venue</td>
        <td>2019 IEEE Conference on Cognitive and Computational Aspects of Situation Management (CogSIMA)</td>
    </tr>
        <tr>
            <td colspan="2">
                <form method="get" action="https://dais-ita.org/sites/default/files/3369_0.pdf">
                    <button type="submit">download paper</button>
                </form>
                <form method="get" action="https://dais-ita.org/sites/default/files/3369_slides_0.pdf">
                    <button type="submit">download presentation</button>
                </form>
            </td>
        </tr>
    </tbody>
</table>
