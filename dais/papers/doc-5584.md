---
layout: splash
permalink: /doc-5584/
title: "Distributed learning preserving model security"
---

# Distributed learning preserving model security

<table>
    <tbody>
    <tr>
        <td>Abstract</td>
        <td>Distributed machine learning employs a central fusion server that coordinates the distributed learning process. Preferably, each of set of learning agents that are typically distributed from one another initially obtains initial parameters for a model from the fusion server. Each agent trains using a dataset local to the agent. The parameters that result from this local training (for a current iteration) are then passed back to the fusion server in a secure manner, and a partial homomorphic encryption scheme is then applied. In particular, the fusion server fuses the parameters from all the agents, and it then shares the results with the agents for a next iteration. In this approach, the model parameters are secured using the encryption scheme, thereby protecting the privacy of the training data, even from the fusion server itself.</td>
    </tr>
    <tr>
        <td>Authors</td>
        <td>
            <ul>
                <li>Dinesh Verma (IBM US)</li>
                <li>Supriyo Chakraborty (IBM US)</li>
                <li>Changchang Liu (IBM US)</li>
            </ul>
        </td>
    </tr>
    <tr>
        <td>Date</td>
        <td>Apr-2020</td>
    </tr>
    <tr>
        <td>Venue</td>
        <td>U.S. Patent Application 16/164,846, filed October 19, 2018 [<a href="https://patents.google.com/patent/US20200125739A1/en">link</a>]</td>
    </tr>
        <tr>
            <td colspan="2">
                <form method="get" action="https://patents.google.com/patent/US20200125739A1/en">
                    <button type="submit">download paper</button>
                </form>
            </td>
        </tr>
    </tbody>
</table>
