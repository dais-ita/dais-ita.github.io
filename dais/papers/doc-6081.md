---
layout: splash
permalink: /doc-6081/
title: "Exploiting Human Perception for Adversarial Attacks"
---

# Exploiting Human Perception for Adversarial Attacks

<table>
    <tbody>
    <tr>
        <td>Abstract</td>
        <td>There has been a significant amount of recent work towards fooling deep-learning-based classifiers, particularly for images, via adversarial inputs that are perceptually similar to be- nign examples. However, researchers typically use minimization of the Lp-norm as a proxy for imperceptibility, an approach that oversimplifies the complexity of real-world images and human visual perception. We exploit the relationship between image features and human perception to propose a Perceptual Loss (PL) metric to better capture human imperceptibly during the generation of adversarial images. By focusing on human perceptible distortion of image features, the metric yields better visual quality adversarial images as our experiments validate. Our results also demonstrate the effectiveness and efficiency of our algorithm.</td>
    </tr>
    <tr>
        <td>Authors</td>
        <td>
            <ul>
                <li>Pengrui Quan (UCLA)</li>
                <li>Mani Srivastava (UCLA)</li>
            </ul>
        </td>
    </tr>
    <tr>
        <td>Date</td>
        <td>Sep-2020</td>
    </tr>
    <tr>
        <td>Venue</td>
        <td>4th Annual Fall Meeting of the DAIS ITA, 2020</td>
    </tr>
        <tr>
            <td colspan="2">
                <form method="get" action="https://ibm.box.com/v/doc-6081-paper">
                    <button type="submit">download paper</button>
                </form>
                <form method="get" action="https://ibm.box.com/v/doc-6081-slides">
                    <button type="submit">download presentation</button>
                </form>
            </td>
        </tr>
    </tbody>
</table>
