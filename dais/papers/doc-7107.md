---
layout: splash
permalink: /doc-7107/
title: "Explainable to whom? Why audience matters when building AI systems that can explain themselves"
---

# Explainable to whom? Why audience matters when building AI systems that can explain themselves

<table>
    <tbody>
    <tr>
        <td>Abstract</td>
        <td>Recent high-profile cases have highlighted the need for artificial intelligence (AI) systems to explain their outputs, to assure users that these systems are functioning appropriately, including being free from harmful biases. There is a large and active multidisciplinary research and development community attempting to address this problem, but one issue that has been neglected is consideration of the audiences for AI system explanations. This talk looked at different roles that humans play in relation to AI systems, and how explanations need to be crafted differently for different kinds of recipients.</td>
    </tr>
    <tr>
        <td>Authors</td>
        <td>
            <ul>
                <li>Alun Preece (Cardiff)</li>
            </ul>
        </td>
    </tr>
    <tr>
        <td>Date</td>
        <td>Mar-2021/td>
    </tr>
    <tr>
        <td>Venue</td>
        <td>Wales Institute of Social and Economic Research and Data, and Department for Work and Pensions Areas of Research Interest (ARI) Workshop</td>
    </tr>
    <tr>
        <td colspan="2">
            <form method="get" action="https://www.spiedigitallibrary.org/conference-proceedings-of-spie/11746/117461Y/From-social-networks-to-negative-ties--refining-analysis-for/10.1117/12.2587501.short">
                <button type="submit">download paper</button>
            </form>
        </td>
    </tr>
    </tbody>
</table>
