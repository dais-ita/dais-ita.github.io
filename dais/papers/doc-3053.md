---
layout: splash
permalink: /doc-3053/
title: "Multimodal Explanations for AI-based Multisensor Fusion"
---

# Multimodal Explanations for AI-based Multisensor Fusion

<table>
    <tbody>
    <tr>
        <td>Abstract</td>
        <td>The recent resurgence in the effectiveness of artificial intelligence (AI) and machine learning (ML) techniques for image, text and signal processing has come with a growing recognition that these techniques are “inscrutable”: they can be hard for users to trust because they lack effective means of generating explanations for their outputs. Consequently, there is currently a great deal of research and development addressing this problem, producing a sizeable number of proposed explanation techniques for AI/ML approaches operating on a variety of data modalities. However, a problem that has received less attention is: what modality of explanation to choose for a particular user and task? For example, many techniques attempt to produce visualizations of the workings of an ML model, e.g., so-called “saliency maps” for a deep neural network, but there may be multiple reasons why this mode of explanation might not be appropriate for a user, including: (i) they may be operating at the edge of the network with a device that is not suited to receiving or displaying such a visualization; (ii) it may not be appropriate for security reasons to send them a visualization derived from the source imagery (e.g., if the location of the camera system is sensitive); (iii) this kind of explanation may be “too low level” for that user's needs – they may require something more “causal”, for example. One approach that may address all three of these example issues would be to map the explanation from a visualization to a textual rationalization. In this paper we explore this issue of generating explanations in a range of modalities in the context of AI/ML services that operate on multisensor data and show that a “grammar-based” approach that separates atomic explanation-generation and communication actions offers sufficient scope and flexibility to address a set of mission scenarios.</td>
    </tr>
    <tr>
        <td>Authors</td>
        <td>
            <ul>
                <li>Dave Braines (IBM UK)</li>
                <li>Alun Preece (Cardiff)</li>
                <li>Dan Harborne (Cardiff)</li>
            </ul>
        </td>
    </tr>
    <tr>
        <td>Date</td>
        <td>Nov-2018</td>
    </tr>
    <tr>
        <td>Venue</td>
        <td>NATO SET-262, Budapest, 5-6 Nov 2018</td>
    </tr>
        <tr>
            <td colspan="2">
                <form method="get" action="https://ibm.box.com/v/doc-3053-paper">
                    <button type="submit">download paper</button>
                </form>
                <form method="get" action="https://ibm.box.com/v/doc-3053-slides">
                    <button type="submit">download presentation</button>
                </form>
            </td>
        </tr>
    </tbody>
</table>
